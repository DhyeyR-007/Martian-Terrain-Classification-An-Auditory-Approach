{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["import os\n","import numpy as np\n","np.random.seed(0)\n","import matplotlib.pyplot as plt\n","%matplotlib inline\n","from pylab import *\n","from keras.models import Sequential\n","from keras.optimizers import Adam\n","from keras.layers import Conv2D, ZeroPadding2D, Activation, Input, concatenate\n","from keras.models import Model\n","from keras.datasets import mnist\n","\n","\n","from keras.layers.pooling import MaxPooling2D\n","from keras.layers.core import Lambda, Flatten, Dense\n","from keras.initializers import glorot_uniform,he_uniform\n","\n","# from keras.engine.topology import Layer\n","from tensorflow.keras.layers import Layer, InputSpec\n","from keras.regularizers import l2\n","from keras import backend as K\n","from keras.utils import plot_model,normalize\n","\n","from sklearn.metrics import roc_curve,roc_auc_score"],"metadata":{"id":"oz6s8P3oVm--"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!pip install librosa\n","!pip install pydub"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ihBQKuf_gYzU","outputId":"c5a6fc65-3eef-4712-92bd-201503ee3ac0"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: librosa in /usr/local/lib/python3.9/dist-packages (0.10.0.post2)\n","Requirement already satisfied: scikit-learn>=0.20.0 in /usr/local/lib/python3.9/dist-packages (from librosa) (1.2.2)\n","Requirement already satisfied: joblib>=0.14 in /usr/local/lib/python3.9/dist-packages (from librosa) (1.1.1)\n","Requirement already satisfied: numpy!=1.22.0,!=1.22.1,!=1.22.2,>=1.20.3 in /usr/local/lib/python3.9/dist-packages (from librosa) (1.22.4)\n","Requirement already satisfied: pooch<1.7,>=1.0 in /usr/local/lib/python3.9/dist-packages (from librosa) (1.6.0)\n","Requirement already satisfied: soundfile>=0.12.1 in /usr/local/lib/python3.9/dist-packages (from librosa) (0.12.1)\n","Requirement already satisfied: typing-extensions>=4.1.1 in /usr/local/lib/python3.9/dist-packages (from librosa) (4.5.0)\n","Requirement already satisfied: numba>=0.51.0 in /usr/local/lib/python3.9/dist-packages (from librosa) (0.56.4)\n","Requirement already satisfied: soxr>=0.3.2 in /usr/local/lib/python3.9/dist-packages (from librosa) (0.3.4)\n","Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.9/dist-packages (from librosa) (4.4.2)\n","Requirement already satisfied: lazy-loader>=0.1 in /usr/local/lib/python3.9/dist-packages (from librosa) (0.2)\n","Requirement already satisfied: audioread>=2.1.9 in /usr/local/lib/python3.9/dist-packages (from librosa) (3.0.0)\n","Requirement already satisfied: msgpack>=1.0 in /usr/local/lib/python3.9/dist-packages (from librosa) (1.0.5)\n","Requirement already satisfied: scipy>=1.2.0 in /usr/local/lib/python3.9/dist-packages (from librosa) (1.10.1)\n","Requirement already satisfied: llvmlite<0.40,>=0.39.0dev0 in /usr/local/lib/python3.9/dist-packages (from numba>=0.51.0->librosa) (0.39.1)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.9/dist-packages (from numba>=0.51.0->librosa) (67.6.0)\n","Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.9/dist-packages (from pooch<1.7,>=1.0->librosa) (2.27.1)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.9/dist-packages (from pooch<1.7,>=1.0->librosa) (23.0)\n","Requirement already satisfied: appdirs>=1.3.0 in /usr/local/lib/python3.9/dist-packages (from pooch<1.7,>=1.0->librosa) (1.4.4)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.9/dist-packages (from scikit-learn>=0.20.0->librosa) (3.1.0)\n","Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.9/dist-packages (from soundfile>=0.12.1->librosa) (1.15.1)\n","Requirement already satisfied: pycparser in /usr/local/lib/python3.9/dist-packages (from cffi>=1.0->soundfile>=0.12.1->librosa) (2.21)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests>=2.19.0->pooch<1.7,>=1.0->librosa) (2022.12.7)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests>=2.19.0->pooch<1.7,>=1.0->librosa) (3.4)\n","Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests>=2.19.0->pooch<1.7,>=1.0->librosa) (2.0.12)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests>=2.19.0->pooch<1.7,>=1.0->librosa) (1.26.15)\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting pydub\n","  Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n","Installing collected packages: pydub\n","Successfully installed pydub-0.25.1\n"]}]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YmwO1pWjgq7O","outputId":"7ebccf8d-3bad-419b-96e8-04e1050b9702"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"markdown","source":["# COMPARISON METRICS"],"metadata":{"id":"OtbRmdU6VnYO"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"hhCF6HbNU3Ov"},"outputs":[],"source":["##### METRICS ########\n","\n","import numpy as np\n","\n","def calc_euclidean(actual, predic):\n","    return np.sqrt(np.sum((actual - predic) ** 2))\n","\n","def calc_mape(actual, predic):\n","    return np.mean(np.abs((actual - predic) / actual))\n","    \n","def calc_correlation(actual, predic):\n","    a_diff = actual - np.mean(actual)\n","    p_diff = predic - np.mean(predic)\n","    numerator = np.sum(a_diff * p_diff)\n","    denominator = np.sqrt(np.sum(a_diff ** 2)) * np.sqrt(np.sum(p_diff ** 2))\n","    return numerator / denominator\n","\n","def compute_similarity(ref_rec,input_rec,weightage=[1,1,1]):\n","    ## Time domain similarity\n","    ref_time = np.correlate(ref_rec,ref_rec)\n","    inp_time = np.correlate(ref_rec,input_rec)\n","    diff_time = abs(ref_time-inp_time)\n","    \n","    ## Freq domain similarity\n","    ref_freq = np.correlate(np.fft.fft(ref_rec),np.fft.fft(ref_rec)) \n","    inp_freq = np.correlate(np.fft.fft(ref_rec),np.fft.fft(input_rec))\n","    diff_freq = abs(ref_freq-inp_freq)\n","    \n","    ## Power similarity\n","    ref_power = np.sum(ref_rec**2)\n","    inp_power = np.sum(input_rec**2)\n","    diff_power = abs(ref_power-inp_power)\n","    \n","    return float(weightage[0]*diff_time+weightage[1]*diff_freq+weightage[2]*diff_power)"]},{"cell_type":"markdown","source":["# DATA LOADING"],"metadata":{"id":"UWh93fc7Vv2s"}},{"cell_type":"code","source":["###### DATA LOADING ########\n","import pandas as pd\n","import os\n","import librosa\n","\n","data = []\n","dataSr = []\n","\n","## Here load all the audio files in the forms of plottable arrays and their correspondign sampling rates in a list\n","for filename in os.listdir(\"/content/drive/MyDrive/ROB 590/Audio files/4_RovAud_split\"):\n","    rover = None\n","    sr = None\n","\n","    if filename.endswith(\".wav\") & filename.startswith(\"chunk\"): \n","        rover, sr = librosa.load(\"/content/drive/MyDrive/ROB 590/Audio files/4_RovAud_split\" + '/'+ filename)\n","        data.append(rover)\n","        dataSr.append(sr)\n","\n","print(len(data))\n","print(len(dataSr))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2fbHbM4FU7k5","outputId":"a40a19e3-25a1-4b44-d37c-6fbfadf91b2c"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["60\n","60\n"]}]},{"cell_type":"markdown","source":["# DATASET CREATION"],"metadata":{"id":"IQDgOnHcV03K"}},{"cell_type":"code","source":["######## ANCHOR, POSITIVE & NEGATIVE DATASET CREATION #########\n","\n","i = 0\n","anchor = []\n","positive = []\n","negative = []\n","for i in range(0, len(data), 3):\n","\n","      a,b = None, None\n","\n","### Any one ###  \n","      if compute_similarity(data[i], data[i+1]) > compute_similarity(data[i+1], data[i]):\n","          a = [compute_similarity(data[i], data[i+1]), data[i], data[i+1]]\n","          \n","      else:\n","          a = [compute_similarity(data[i+1], data[i]), data[i], data[i+1]]\n","\n","\n","### Any one ###\n","      if compute_similarity(data[i], data[i+2]) > compute_similarity(data[i+2], data[i]):\n","          b = [compute_similarity(data[i], data[i+2]), data[i], data[i+2]]\n","          \n","      else:\n","          b = [compute_similarity(data[i+2], data[i]), data[i], data[i+2]]\n","\n","\n","\n","### Any one ###\n","      if compute_similarity(data[i+2], data[i+1]) > compute_similarity(data[i+1], data[i+2]):\n","          c = [compute_similarity(data[i+2], data[i+1]), data[i+2], data[i+1]]\n","          \n","      else:\n","          c = [compute_similarity(data[i+1], data[i+2]), data[i+2], data[i+1]]\n","\n","\n","\n","      Max_Similarity = max(a[0],b[0],c[0])\n","\n","      if Max_Similarity == a[0]:\n","        anchor.append(a[1])\n","        positive.append(a[2])\n","        negative.append(b[2])\n","\n","      elif Max_Similarity == b[0]:\n","        anchor.append(b[1])\n","        positive.append(b[2])\n","        negative.append(a[2])\n","\n","      elif Max_Similarity == c[0]:\n","        anchor.append(c[2])\n","        positive.append(c[1])\n","        negative.append(a[1])\n","\n","\n","\n","## Reshaping ##\n","for i in range(len(anchor)):\n","  anchor[i] = anchor[i].reshape(200,-1,1)\n","  positive[i] = positive[i].reshape(200,-1,1)\n","  negative[i] =  negative[i].reshape(200,-1,1)\n","\n","\n"],"metadata":{"id":"tNEMdU0SU92o"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# TRIPLETS GROUPING"],"metadata":{"id":"3vXDDGrZV8vK"}},{"cell_type":"code","source":["def group_triplets(percent):\n","    \"\"\"\n","    Input:\n","    batch_size --> integer \n","\n","    Output:\n","    triplets --> list containing 3 tensors A,P,N of shape (batch_size,w,h,c)\n","\n","    \"\"\"\n","    batch = len(anchor)\n","    number_test = int(batch * (percent/100))\n","    number_train = int(batch-number_test)\n","\n","    w, h, c = anchor[0].shape  # W,H,C\n","    triplets_train=[np.zeros((number_train,w,h,c)) for i in range(3)]\n","    \n","\n","# Train\n","    for i in range(number_train):\n","        triplets_train[0][i] =  anchor[i]\n","        triplets_train[1][i] =  positive[i]\n","        triplets_train[2][i] =  negative[i]\n","  \n","\n","\n","# Test\n","    triplets_test=[np.zeros((number_test,w,h,c)) for i in range(3)]\n","    for i in range(number_test):\n","        triplets_test[0][i] =  anchor[batch-1 - i]\n","        triplets_test[1][i] =  positive[batch-1 - i]\n","        triplets_test[2][i] =  negative[batch-1 - i]\n","  \n","\n","    return triplets_train,triplets_test"],"metadata":{"id":"fiW4tOBAVE4C"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Sanity Check\n","triplets,tri = group_triplets(percent=10)\n","\n","# print(\"Checking batch width, should be 3 : \",len(triplets))\n","print(\"Train___Shapes in the batch A:{0} P:{1} N:{2}\".format(triplets[0].shape, triplets[1].shape, triplets[2].shape))\n","print(\"Test____Shapes in the batch A:{0} P:{1} N:{2}\".format(tri[0].shape, tri[1].shape, tri[2].shape))\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"G5_9HVxhVG8r","outputId":"89548242-d04b-4614-bc20-f6e3ba68c45f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Train___Shapes in the batch A:(18, 200, 441, 1) P:(18, 200, 441, 1) N:(18, 200, 441, 1)\n","Test____Shapes in the batch A:(2, 200, 441, 1) P:(2, 200, 441, 1) N:(2, 200, 441, 1)\n"]}]},{"cell_type":"markdown","source":["# MODEL ARCHITECTURE, TRIPLET LOSS & LAYERS"],"metadata":{"id":"SNR6isiJWZ5Y"}},{"cell_type":"code","source":["def network_architecture(input_shape, embeddingsize):\n","    '''\n","    Input : \n","            input_shape : shape of input images\n","            embeddingsize : vectorsize used to encode our picture   \n","    '''\n","     # Convolutional Neural Network\n","    network = Sequential()\n","\n","    network.add(Conv2D(filters=16, kernel_size=5, padding='same', activation='relu'))\n","    network.add(MaxPooling2D(2,strides=2))\n","\n","    network.add(Flatten())\n","    network.add(Dense(128, activation='relu',\n","                   kernel_regularizer=l2(1e-3),\n","                   kernel_initializer='he_uniform'))\n","    \n","    \n","    network.add(Dense(embeddingsize, activation=None,\n","                   kernel_regularizer=l2(1e-3),\n","                   kernel_initializer='he_uniform'))\n","    \n","    #Force the encoding to live on the d-dimentional hypershpere\n","    network.add(Lambda(lambda x: K.l2_normalize(x,axis=-1)))\n","    \n","    return network"],"metadata":{"id":"FPyxnmh2WPa1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class TripletLossLayer(Layer):\n","    def __init__(self, alpha, **kwargs):\n","        self.alpha = alpha\n","        super(TripletLossLayer, self).__init__(**kwargs)\n","    \n","    def triplet_loss(self, inputs):\n","        anchor, positive, negative = inputs\n","        p_dist = K.sum(K.square(anchor-positive), axis=-1)\n","        n_dist = K.sum(K.square(anchor-negative), axis=-1)\n","        return K.sum(K.maximum(p_dist - n_dist + self.alpha, 0), axis=0)\n","    \n","    def call(self, inputs):\n","        loss = self.triplet_loss(inputs)\n","        self.add_loss(loss)\n","        return loss"],"metadata":{"id":"8uUg3NUOWLsq"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def Model_Architecture_Start(input_shape, network, margin=0.2):\n","    '''\n","        Input: \n","          network --> Neural network to train outputing embeddings\n","          input_shape --> shape of input audio\n","          margin --> minimal distance between Anchor-Positive and Anchor-Negative for the lossfunction (alpha)\n","    \n","    '''\n","     # Define the tensors for the three input audios\n","    anchor_ip = Input(input_shape, name=\"anchor_input\")\n","    positive_ip = Input(input_shape, name=\"positive_input\")\n","    negative_ip = Input(input_shape, name=\"negative_input\") \n","    \n","    # Generate the encodings (feature vectors) for the three audio files\n","    encoded_a = network(anchor_ip)\n","    encoded_p = network(positive_ip)\n","    encoded_n = network(negative_ip)\n","    \n","    #TripletLoss Layer\n","    loss_layer = TripletLossLayer(alpha=margin,name='triplet_loss_layer')([encoded_a,encoded_p,encoded_n])\n","    \n","    # Connect the inputs with the outputs\n","    network_train = Model(inputs=[anchor_ip,positive_ip,negative_ip],outputs=loss_layer)\n","    \n","    # return the model\n","    return network_train"],"metadata":{"id":"yNY5hVovVgEH"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Driver code for calling out the neural net architecture\n","row, col,channel = 200, 441, 1\n","input_shape = (row, col, channel)\n","\n","network = network_architecture(input_shape,embeddingsize=4)\n","network_train = Model_Architecture_Start(input_shape,network)\n","optimizer = Adam(lr = 0.00006)\n","network_train.compile(optimizer=optimizer)\n","network_train.summary()\n","# plot_model(network_train,show_shapes=True, show_layer_names=True, to_file='02 model.png')\n","print(network_train.metrics_names)\n","n_iteration=0\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"uFM_V3n4ftkM","outputId":"d30f40c1-9575-481f-8313-d47a2984d7f7"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"model\"\n","__________________________________________________________________________________________________\n"," Layer (type)                   Output Shape         Param #     Connected to                     \n","==================================================================================================\n"," anchor_input (InputLayer)      [(None, 200, 441, 1  0           []                               \n","                                )]                                                                \n","                                                                                                  \n"," positive_input (InputLayer)    [(None, 200, 441, 1  0           []                               \n","                                )]                                                                \n","                                                                                                  \n"," negative_input (InputLayer)    [(None, 200, 441, 1  0           []                               \n","                                )]                                                                \n","                                                                                                  \n"," sequential (Sequential)        (None, 4)            45057060    ['anchor_input[0][0]',           \n","                                                                  'positive_input[0][0]',         \n","                                                                  'negative_input[0][0]']         \n","                                                                                                  \n"," triplet_loss_layer (TripletLos  ()                  0           ['sequential[0][0]',             \n"," sLayer)                                                          'sequential[1][0]',             \n","                                                                  'sequential[2][0]']             \n","                                                                                                  \n","==================================================================================================\n","Total params: 45,057,060\n","Trainable params: 45,057,060\n","Non-trainable params: 0\n","__________________________________________________________________________________________________\n","[]\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.9/dist-packages/keras/optimizers/optimizer_v2/adam.py:117: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n","  super().__init__(name, **kwargs)\n"]}]},{"cell_type":"markdown","source":["# TRAINING"],"metadata":{"id":"3TDOxi-_WzXC"}},{"cell_type":"code","source":["print(\"Starting training process!\")\n","print(\"-------------------------------------\")\n","triplets,_ = group_triplets(20)\n","loss = network_train.fit(triplets, epochs=20,steps_per_epoch=5, validation_split=0.2)"],"metadata":{"id":"Hym21Pj_VPKr"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Embeddings"],"metadata":{"id":"7s-NLPQAjz7Y"}},{"cell_type":"code","source":["def distance_metric(network, triplets_testing):\n","\n","\n","    n,w,h,c = triplets_testing[0].shape\n","\n","\n","    for j in range(len(triplets_testing[0])):\n","\n","        image_A = network.predict(np.expand_dims(triplets_testing[0][j,:,:,:],axis=0))\n","        image_P = network.predict(np.expand_dims(triplets_testing[1][j,:,:,:],axis=0))\n","        image_N = network.predict(np.expand_dims(triplets_testing[2][j,:,:,:],axis=0))\n","        \n","        dist_AP = calc_euclidean(image_A, image_P)\n","        dist_AN = calc_euclidean(image_A, image_N)\n","\n","\n","        print(\"{0}th Batch\".format(j))\n","        print(\"Distance between Anchor & Positive {0}\".format(dist_AP))\n","        print(\"Distance between Anchor & Negative {0}\".format(dist_AN))\n","\n","\n","\n","training,testing = group_triplets(20)\n","distance_metric(network,testing)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"D4ok7feVfeXj","outputId":"8635e8d4-5e8a-41d7-b80a-8526840888b9"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 66ms/step\n","1/1 [==============================] - 0s 55ms/step\n","1/1 [==============================] - 0s 66ms/step\n","0th Batch\n","Distance between Anchor & Positive 0.14198830723762512\n","Distance between Anchor & Negative 0.28337201476097107\n","1/1 [==============================] - 0s 66ms/step\n","1/1 [==============================] - 0s 57ms/step\n","1/1 [==============================] - 0s 57ms/step\n","1th Batch\n","Distance between Anchor & Positive 0.24449080228805542\n","Distance between Anchor & Negative 0.5556584000587463\n","1/1 [==============================] - 0s 64ms/step\n","1/1 [==============================] - 0s 57ms/step\n","1/1 [==============================] - 0s 57ms/step\n","2th Batch\n","Distance between Anchor & Positive 0.11453274637460709\n","Distance between Anchor & Negative 0.22129596769809723\n","1/1 [==============================] - 0s 102ms/step\n","1/1 [==============================] - 0s 85ms/step\n","1/1 [==============================] - 0s 84ms/step\n","3th Batch\n","Distance between Anchor & Positive 0.4462537467479706\n","Distance between Anchor & Negative 0.21703052520751953\n"]}]}]}